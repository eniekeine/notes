{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def print_tensor_detail(t : torch.tensor):\n",
    "    print(\"type : \", type(t))\n",
    "    print(\"t : \", t, sep='\\n')\n",
    "    print(\"t.shape : \", t.shape)\n",
    "    print(\"t.dtype : \", t.dtype)\n",
    "    print(\"torch.is_tesnor(t) : \", torch.is_tensor(t))\n",
    "    print(\"torch.is_storage(t) : \", torch.is_storage(t))\n",
    "    print(\"torch.is_complex(t) : \", torch.is_complex(t))\n",
    "    print(\"torch.is_conj(t) : \", torch.is_conj(t))\n",
    "    print(\"torch.is_floating_point(t) : \", torch.is_floating_point(t))\n",
    "    print(\"torch.numel(t) : \", torch.numel(t))\n",
    "    if torch.numel(t) == 1:\n",
    "        print(\"torch.is_nonzero(t) : \", torch.is_nonzero(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor\n",
    "\n",
    "- 대수학에서 텐서(Tensor)란 수를 담을 수 있는 다차원 배열이다.\n",
    "- 텐서는 스칼라, 벡터, 행렬, 그 이상의 차원을 가진 구조체를 모두 아울러 부르는 말이다.\n",
    "- 텐서 안의 어떤 숫자를 고르기 위해 필요한 인덱스의 수를 랭크라 한다.\n",
    "  - 스칼라(Scalar): 랭크 0의 텐서이다. 1 개의 값을 나타낸다.\n",
    "    - 예를 들어 숫자 $t=3.14159$.\n",
    "    - 배열이 아니므로 인덱스가 필요없다.\n",
    "  - 벡터(Vector): 랭크 1의 텐서이다. 1차원 값의 배열이다.\n",
    "    - 예를 들어 $t=[1, 2, 3]$.\n",
    "    - 두 번째 수 $2$를 얻어내려면 `t[1]`과 같이 한 개의 인덱스가 필요하다.\n",
    "  - 행렬(Matrix): 랭크 2의 텐서이다. 2차원 값의 배열을 나타낸다.\n",
    "    - 예를 들어 $t=\\begin{bmatrix}1 & 2 \\\\3 & 4\\end{bmatrix}$.\n",
    "    - 2행 1열에 배정된 숫자 $3$을 얻어내려면 `t[1, 0]`과 같이 두 개의 인덱스가 필요하다.\n",
    "  - 고차원 텐서(Higher-order tensors): 랭크 3 이상의 텐서이다. 여러 차원의 값의 배열이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.Tensor\n",
    "\n",
    "- torch 패키지는 텐서 객체와 연산을 지원한다.\n",
    "- torch의 텐서는 `torch.tensor()` 메서드로 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch.tensor(\n",
    "#     data, \n",
    "#     *, \n",
    "#     dtype=None, \n",
    "#     device=None, \n",
    "#     requires_grad=False, \n",
    "#     pin_memory=False) → Tensor\n",
    "torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 값이 하나 뿐인 스칼라 텐서는 값이 하나만 들어있는 배열을 `data` 인수로 넣어 정의할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type :  <class 'torch.Tensor'>\n",
      "t : \n",
      "tensor([3.1416])\n",
      "t.shape :  torch.Size([1])\n",
      "t.dtype :  torch.float32\n",
      "torch.is_tesnor(t) :  True\n",
      "torch.is_storage(t) :  False\n",
      "torch.is_complex(t) :  False\n",
      "torch.is_conj(t) :  False\n",
      "torch.is_floating_point(t) :  True\n",
      "torch.numel(t) :  1\n",
      "torch.is_nonzero(t) :  True\n"
     ]
    }
   ],
   "source": [
    "print_tensor_detail(torch.tensor([3.14159]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 벡터를 나타내는 텐서는 값이 여럿 들어있는 배열을 `data`인수로 넣어 정의할 수 있다.\n",
    "- 벡터를 나타내는 텐서는 `t[index]`로 내부에 들어있는 스칼라 탠서를 액세스 할 수 있다.\n",
    "- 파이선의 일반 배열과 동일하게 음수 인덱싱이 가능하며, 슬라이스도 할 수 있다.\n",
    "- 텐서는 가변형이다. 인덱싱과 함께 배정 연산을 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type :  <class 'torch.Tensor'>\n",
      "t : \n",
      "tensor([1, 2, 3, 4])\n",
      "t.shape :  torch.Size([4])\n",
      "t.dtype :  torch.int64\n",
      "torch.is_tesnor(t) :  True\n",
      "torch.is_storage(t) :  False\n",
      "torch.is_complex(t) :  False\n",
      "torch.is_conj(t) :  False\n",
      "torch.is_floating_point(t) :  False\n",
      "torch.numel(t) :  4\n",
      "t[0] :  tensor(1)\n",
      "t[3] :  tensor(4)\n",
      "t[-1] :  tensor(4)\n",
      "t[-4] :  tensor(1)\n",
      "t[:2] :  tensor([1, 2])\n",
      "t[1:2] :  tensor([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 3, 4])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1, 2, 3, 4])\n",
    "print_tensor_detail(t)\n",
    "print(\"t[0] : \", t[0])\n",
    "print(\"t[3] : \", t[3])\n",
    "# print(\"t[4] : \", t[4]) # IndexError\n",
    "print(\"t[-1] : \", t[-1])\n",
    "print(\"t[-4] : \", t[-4])\n",
    "# print(\"t[-5] : \", t[-5]) # IndexError\n",
    "print(\"t[:2] : \", t[:2])\n",
    "print(\"t[1:2] : \", t[1:2])\n",
    "\n",
    "t[0] = 0\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬을 나타내는 텐서는 배열의 배열을 `data`인수로 넣어 정의할 수 있다.\n",
    "- 바깥쪽 배열의 아이템은 각각의 행을 나타낸다.\n",
    "- 따라서 다음 코드는 $\\begin{bmatrix}1&2&3\\\\4&5&6\\end{bmatrix}$을 정의한다.\n",
    "- 행렬을 나타내는 텐서는 `t[index_row]`로 행 벡터 텐서를 구할 수 있다.\n",
    "- 행렬을 나타내는 텐서는 `t[index_row, index_column]`으로 각 원소의 스칼라 텐서를 구할 수 있다.\n",
    "- 행렬을 나타내는 텐서는 `t[:, index_column]`으로 열 벡터 텐서를 슬라이스 할 수 있다.\n",
    "- 행렬을 나타내는 텐서는 `t[a:b, c:d]`로 $(b-a) \\times (d-c)$크기의 부분 행렬을 슬라이스 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type :  <class 'torch.Tensor'>\n",
      "t : \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "t.shape :  torch.Size([2, 3])\n",
      "t.dtype :  torch.int64\n",
      "torch.is_tesnor(t) :  True\n",
      "torch.is_storage(t) :  False\n",
      "torch.is_complex(t) :  False\n",
      "torch.is_conj(t) :  False\n",
      "torch.is_floating_point(t) :  False\n",
      "torch.numel(t) :  6\n",
      "t[0] :  tensor([1, 2, 3])\n",
      "t[1] :  tensor([4, 5, 6])\n",
      "t[0, 0] :  tensor(1)\n",
      "t[1, 2] :  tensor(6)\n",
      "t[:,0] :  tensor([1, 4])\n",
      "t[:,1] :  tensor([2, 5])\n",
      "t[:,2] :  tensor([3, 6])\n",
      "t[0:1, 1:3] :  tensor([[2, 3]])\n"
     ]
    }
   ],
   "source": [
    "# 1 2 3\n",
    "# 4 5 6\n",
    "t = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print_tensor_detail(t)\n",
    "print(\"t[0] : \", t[0]) # 1행\n",
    "print(\"t[1] : \", t[1]) # 2행\n",
    "print(\"t[0, 0] : \", t[0, 0]) # 1행 1열\n",
    "print(\"t[1, 2] : \", t[1, 2]) # 2행 3열\n",
    "print(\"t[:,0] : \", t[:,0]) # 1열\n",
    "print(\"t[:,1] : \", t[:,1]) # 2열\n",
    "print(\"t[:,2] : \", t[:,2]) # 3열\n",
    "print(\"t[0:1, 1:3] : \", t[0:1, 1:3]) # (1 x 2) 크기의 부분 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단위 행렬을 만들고 싶다면 `torch.eye`함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(0, 0))\n",
      "tensor([[1.]])\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# print(torch.eye(-1)) # RuntimeError\n",
    "print(torch.eye(0))\n",
    "print(torch.eye(1))\n",
    "print(torch.eye(2))\n",
    "print(torch.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬 텐서를 정의할 경우, 각 행의 길이는 서로 같아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 1 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[191], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([\n\u001b[0;32m      2\u001b[0m     [\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m],\n\u001b[0;32m      3\u001b[0m     [\u001b[39m4\u001b[39;49m, \u001b[39m5\u001b[39;49m]\n\u001b[0;32m      4\u001b[0m ])\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5]\n",
    "]) # ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tensor()`의 `dtype` 인수로 데이터의 형식을 직접 지정할 수도 있다.\n",
    "- `dtype=None`인 경우 데이터로 부터 `dtype`을 추론한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) torch.int64\n",
      "tensor([1., 2., 3.]) torch.float32\n",
      "tensor([1.0000, 2.0000, 2.4000]) torch.float32\n",
      "tensor([ True, False]) torch.bool\n",
      "tensor([False,  True,  True]) torch.bool\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor() # TypeError: tensor() missing 1 required positional arguments: \"data\"\n",
    "print(torch.tensor([1,2,3]), torch.tensor([1,2,3]).dtype)\n",
    "print(torch.tensor([1.0,2.0,3.0]), torch.tensor([1.0,2.0,3.0]).dtype)\n",
    "print(torch.tensor([1,2,2.4]), torch.tensor([1,2,2.4]).dtype)\n",
    "print(torch.tensor([True,False]), torch.tensor([True, False]).dtype)\n",
    "print(torch.tensor([0,1,2], dtype=torch.bool), torch.tensor([1,2,3], dtype=torch.bool).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tensor()`의 `device` 인수로 텐서가 배정될 장치를 결정할 수 있다.\n",
    "- `device=None`인 경우 `torch.set_default_device()`로 미리 설정해둔 기본값을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([1,2,3]).device)\n",
    "print(torch.tensor([1,2,3], device=\"cpu\").device)\n",
    "print(torch.tensor([1,2,3], device=\"cuda\").device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.Tensor()` 생성자를 직접 호출하여 텐서를 생성할 수도 있으나,\n",
    "- `torch.Tensor()`는 입력받은 데이터의 형식에 상관없이 `dtype`이 `torch.FloatTensor()`로 고정된다.\n",
    "- 그런 이유로 `torch.tensor()`를 사용하는 편이 더 낫다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) torch.int64\n",
      "tensor([1., 2., 3.]) torch.float32\n",
      "tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = [1,2,3]\n",
    "tensor = torch.tensor(data)\n",
    "Tensor = torch.Tensor(data)\n",
    "print(tensor, tensor.dtype)\n",
    "print(Tensor, Tensor.dtype)\n",
    "print(torch.Tensor([True, False]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서의 규격은 `tensor.shape`로 구할 수 있다.\n",
    "- 규격은 고차원의 규격부터 순서대로 나타난다.\n",
    "- 예를 들어 다음 코드의 텐서 `t`는 랭크 3의 텐서이며, 그 크기는 $2 \\times 3 \\times 4$이다. \n",
    "- 인덱싱을 할 때도 고차원의 인덱스부터 순서대로 쓴다.\n",
    "- 따라서 $7$을 구하려면 `t[0, 1, 2]`로 쓴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "tensor(7.)\n"
     ]
    }
   ],
   "source": [
    "t = torch.Tensor([[\n",
    "    [1,2,3,4],\n",
    "    [5,6,7,8],\n",
    "    [9,10,11,12],\n",
    "],\n",
    "[\n",
    "    [-1,-2,-3,-4],\n",
    "    [-5,-6,-7,-8],\n",
    "    [-9,-10,-11,-12],\n",
    "]\n",
    "])\n",
    "print(t.shape)\n",
    "print(t[0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.empty()`를 통해 값을 초기화하지 않은 텐서를 만들 수 있다.\n",
    "- `torch.zeros()`를 통해 $0$으로 가득한 텐서를 만들 수 있다.\n",
    "- `torch.ones()`를 통해 $1$로 가득한 텐서를 만들 수 있다.\n",
    "- `torch.full(size, fill_value)`를 통해 `fill_value`로 가득한 텐서를 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.empty(2,2) :  tensor([[1.5412e-37, 5.9555e-43],\n",
      "        [5.7397e-42, 0.0000e+00]])\n",
      "torch.zeros(3,2) :  tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "torch.ones(2,3) :  tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.full((3,3), 42) :  tensor([[42, 42, 42],\n",
      "        [42, 42, 42],\n",
      "        [42, 42, 42]])\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.empty(2,2) : \", torch.empty(2, 2))\n",
    "print(\"torch.zeros(3,2) : \", torch.zeros(3 ,2))\n",
    "print(\"torch.ones(2,3) : \", torch.ones(2, 3))\n",
    "print(\"torch.full((3,3), 42) : \", torch.full((3,3), 42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 언급한 `empty()`, `zeros()`, `ones()`, `full()`은 각각의 `_like`버전인 `empty_like()`, `zeros_like()`, `ones_like()`, `full_like()`가 있다. 이 함수들은 텐서의 크기를 받는 대신, 이미 초기화된 다른 텐서를 받아 그 텐서와 같은 크기이지만 값만 각각의 규칙으로 채운 텐서를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.empty_like(sample_tensor) :  tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.zeros_like(sample_tensor) :  tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.ones_like(sample_tensor) :  tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.full_like(sample_tensor, 42) :  tensor([[42., 42., 42.],\n",
      "        [42., 42., 42.],\n",
      "        [42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "sample_tensor = torch.eye(3)\n",
    "print(\"torch.empty_like(sample_tensor) : \", torch.empty_like(sample_tensor))\n",
    "print(\"torch.zeros_like(sample_tensor) : \", torch.zeros_like(sample_tensor))\n",
    "print(\"torch.ones_like(sample_tensor) : \", torch.ones_like(sample_tensor))\n",
    "print(\"torch.full_like(sample_tensor, 42) : \", torch.full_like(sample_tensor, 42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.asarray(obj)`를 통해 임의의 객체를 텐서로 전환할 수 있다.\n",
    "- 특히 `numpy.ndarray`와 같이 파이선의 버퍼 프로토콜을 구현하는 객체인 경우, 데이터를 복사하는 대신 `obj`의 데이터 메모리를 공유한다.\n",
    "- 이 외에도 유사한 함수로 `from_numpy`, `from_dlpack`, `frombuffer`, `as_tensor`, `as_strided` 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "True\n",
      "tensor([1., 2., 3.])\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.7500])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "array = numpy.array([1, 2, 3])\n",
    "print(array)\n",
    "# Shares memory with array 'array'\n",
    "t1 = torch.asarray(array)\n",
    "print(t1)\n",
    "print(array.__array_interface__['data'][0] == t1.data_ptr())\n",
    "# Copies memory due to dtype mismatch\n",
    "t2 = torch.asarray(array, dtype=torch.float32)\n",
    "print(t2)\n",
    "print(array.__array_interface__['data'][0] == t1.data_ptr())\n",
    "\n",
    "scalar = numpy.float64(0.5)\n",
    "torch.asarray(scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.arange(start, end, step)`를 통해 $[\\text{start}, \\text{end})$ 사이의 수를 포함하는 벡터 텐서를 만들 수 있다.\n",
    "- 만들어지는 텐서의 크기는 다음 공식으로 구할 수 있다.\n",
    "$$\\Bigg\\lceil{\\frac{\\text{end} - \\text{start}}{step}}\\Bigg\\rceil$$\n",
    "- 예를 들어, `(0, 10, 2)`가 입력된 경우 크기는 $5$이다.\n",
    "  $$\\Bigg\\lceil{\\frac{\\text{10} - \\text{0}}{2}}\\Bigg\\rceil=5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.arange(0, 10, 2) :  tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.arange(0, 10, 2) : \", torch.arange(0, 10, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원소 사이의 간격 `step`을 지정하여 임의의 크기의 텐서를 구하였던 `arange`와는 반대로,\n",
    "- `torch.linespace(start, end, steps)`는 텐서의 크기를 지정하여 `step`을 계산하도록 한다.\n",
    "- 원소 수열의 일반식은 다음과 같이 정의한다.\n",
    "  $$t : (a_0, a_1 \\cdots a_{steps-1})$$\n",
    "  $$a_i = \\text{start} + \\frac{(\\text{end}-\\text{start})}{\\text{steps}-1} * i$$\n",
    "- 예를 들어 `linespace(3,10,5)`인 경우 각 원소는 다음과 같다.\n",
    "  - $a_0 = 3 + 1.75 * 0 = 3$\n",
    "  - $a_1 = 3 + 1.75 * 1 = 4.75$\n",
    "  - $a_2 = 3 + 1.75 * 2 = 6.5$\n",
    "  - $a_3 = 3 + 1.75 * 3 = 8.25$\n",
    "  - $a_4 = 3 + 1.75 * 4 = 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.linspace(3, 10, 5) :  tensor([ 3.0000,  4.7500,  6.5000,  8.2500, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.linspace(3, 10, 5) : \", torch.linspace(3, 10, steps=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.logspace(start, end, steps, base=10)`는 `linespace`와 사용법이 유사하다.\n",
    "- 다만, 각 원소를 계산할 때 지수의 밑(`base`)을 사용하며, 원소의 값을 계산하는 공식이 다르다.\n",
    "- `logspace`를 통해 생성된 텐서의 원소들은 로그 공간에서 간격이 균등하게 분포한다.\n",
    "- 즉, 인접한 두 원소의 지수의 차가 균일하다는 뜻이다.\n",
    "  $$t : (a_0, a_1 \\cdots a_{steps-1})$$\n",
    "  $$a_i = \\text{base}^{\\text{start} + \\frac{(\\text{end}-\\text{start})}{\\text{steps}-1} * i}$$\n",
    "- 위 공식에서 지수부가 `linespace`의 $a_i$과 동일함을 확인할 수 있다\n",
    "- 예를 들어 `torch.logspace(-10, 10, 5)`인 경우 각 원소는 다음과 같다.\n",
    "  - $a_0 = 10^{-10 + 5 * 0} = 10^{-10}$\n",
    "  - $a_1 = 10^{-10 + 5 * 1} = 10^{-5}$\n",
    "  - $a_2 = 10^{-10 + 5 * 2} = 10^{0}$\n",
    "  - $a_3 = 10^{-10 + 5 * 3} = 10^{5}$\n",
    "  - $a_4 = 10^{-10 + 5 * 4} = 10^{10}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logspace(start=-10, end=10, steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.quantize_per_tensor()`, `torch.quantize_per_channel()`는 텐서의 모든 실수 원소를 정수 양자화(quantize) 한다.\n",
    "- 양자화된 텐서는 `torch.quint8`, `torch.qint8`, `torch.qint32` 세 타입 중 하나의 타입을 가진다.\n",
    "- `torch.dequantize()`는 양자화된 텐서를 32비트 플로트 텐서로 되돌린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.,  0.,  1.,  2.], size=(4,), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10)\n",
      "tensor([ 0, 10, 20, 30], dtype=torch.uint8)\n",
      "(tensor([-1.,  0.], size=(2,), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.10000000149011612,\n",
      "       zero_point=10), tensor([-2.,  2.], size=(2,), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.20000000298023224,\n",
      "       zero_point=20))\n",
      "tensor([-1.,  0.,  1.,  2.], size=(4,), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.10000000149011612,\n",
      "       zero_point=10)\n",
      "================================================================================\n",
      "tensor([[-1.,  0.],\n",
      "        [ 1.,  2.]], size=(2, 2), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_channel_affine,\n",
      "       scale=tensor([0.1000, 0.0100], dtype=torch.float64),\n",
      "       zero_point=tensor([10,  0]), axis=0)\n",
      "tensor([[  0,  10],\n",
      "        [100, 200]], dtype=torch.uint8)\n",
      "================================================================================\n",
      "tensor([[-1.,  0.],\n",
      "        [ 1.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8))\n",
    "print(torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8).int_repr())\n",
    "print(torch.quantize_per_tensor([torch.tensor([-1.0, 0.0]), torch.tensor([-2.0, 2.0])], torch.tensor([0.1, 0.2]), torch.tensor([10, 20]), torch.quint8))\n",
    "print(torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), torch.tensor(0.1), torch.tensor(10), torch.quint8))\n",
    "print(\"=\"*80)\n",
    "x = torch.tensor([[-1.0, 0.0], [1.0, 2.0]])\n",
    "print(torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8))\n",
    "print(torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8).int_repr())\n",
    "print(\"=\"*80)\n",
    "print(torch.dequantize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.complex`는 실수부를 나타내는 텐서와 허수부를 나타내는 텐서를 조합하여 복소수 텐서를 만든다.\n",
    "- 두 텐서의 크기는 서로 같아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type :  <class 'torch.Tensor'>\n",
      "t : \n",
      "tensor([1.+3.j, 2.+4.j])\n",
      "t.shape :  torch.Size([2])\n",
      "t.dtype :  torch.complex64\n",
      "torch.is_tesnor(t) :  True\n",
      "torch.is_storage(t) :  False\n",
      "torch.is_complex(t) :  True\n",
      "torch.is_conj(t) :  False\n",
      "torch.is_floating_point(t) :  False\n",
      "torch.numel(t) :  2\n"
     ]
    }
   ],
   "source": [
    "real = torch.tensor([1, 2], dtype=torch.float32)\n",
    "imag = torch.tensor([3, 4], dtype=torch.float32)\n",
    "z = torch.complex(real, imag)\n",
    "print_tensor_detail(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.polar(abs, angle)`는 다음과 같이 극분해(polar decomposition)을 수행한다.\n",
    "  - ※ 선형대수학과 함수해석학에서 극분해(極分解, 영어: polar decomposition)는 복소수 정사각 행렬 또는 두 복소수 힐베르트 공간 사이의 유계 작용소를, “절댓값”과 “편각”으로 분해하는 과정이다. 여기서, “절댓값” 성분은 항상 음이 아닌 고윳값을 가지는 자기 수반 작용소이며, “편각” 성분은 그 핵의 직교 여공간과 치역 사이의 유니터리 변환을 정의한다.\n",
    "- `abs`는 음수이거나 `NaN`일 수 없다.\n",
    "- `angle`은 무한일 수 없다.\n",
    "\n",
    "$$\n",
    "\\text{out} = abs(\\cos{\\text{angle}} + i\\sin{\\text{angle}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.1232e-17+1.0000j, -1.4142e+00-1.4142j], dtype=torch.complex128)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "abs = torch.tensor([1, 2], dtype=torch.float64)\n",
    "angle = torch.tensor([np.pi / 2, 5 * np.pi / 4], dtype=torch.float64)\n",
    "z = torch.polar(abs, angle)\n",
    "z"
   ]
  },
  {
   "attachments": {
    "488px-Dirac_distribution_CDF.svg.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.heaviside(input, values, *, out=None)`는 텐서에 단위 계단 함수(Heaviside step function)를 적용한다.\n",
    "\n",
    "![488px-Dirac_distribution_CDF.svg.png](attachment:488px-Dirac_distribution_CDF.svg.png)\n",
    "\n",
    "$$\n",
    "\\text{heaviside}(input, values) = \\begin{cases}\n",
    "0&(\\text{if }input < 0)\\\\\n",
    "values&(\\text{if }input = 0)\\\\\n",
    "1&(\\text{if }input > 0)\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5000,  0.0000,  2.0000])\n",
      "========================================\n",
      "values :  tensor([0.5000])\n",
      "heaviside :  tensor([0.0000, 0.5000, 1.0000])\n",
      "========================================\n",
      "values :  tensor([ 1.2000, -2.0000,  3.5000])\n",
      "heaviside :  tensor([ 0., -2.,  1.])\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([-1.5, 0, 2.0])\n",
    "print(input)\n",
    "print(\"=\"*40)\n",
    "values = torch.tensor([0.5])\n",
    "print(\"values : \", values)\n",
    "print(\"heaviside : \", torch.heaviside(input, values))\n",
    "print(\"=\"*40)\n",
    "values = torch.tensor([1.2, -2.0, 3.5])\n",
    "print(\"values : \", values)\n",
    "print(\"heaviside : \", torch.heaviside(input, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.adjoint`는 복소수 행렬을 입력받아 켤레 전치를 구한다.\n",
    "- 켤레 전치는 adjoint 혹은 conjugate transpose 혹은 Hermitian transpose라고도 불린다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.+0.j, 1.+1.j],\n",
      "        [2.+2.j, 3.+3.j]])\n",
      "tensor([[0.-0.j, 2.-2.j],\n",
      "        [1.-1.j, 3.-3.j]])\n",
      "tensor([[ True, False],\n",
      "        [False, False]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4, dtype=torch.float)\n",
    "A = torch.complex(x, x).reshape(2, 2)\n",
    "print(A)\n",
    "print(A.adjoint())\n",
    "print(A.adjoint() == A.mH.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
