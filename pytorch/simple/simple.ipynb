{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝이 풀고자 하는 문제\n",
    "\n",
    "- 일차함수는 기울기 $w$, y-절편 $b$으로 이루어진 함수입니다.\n",
    "  - $f(x)=wx+b$\n",
    "- 예를 들어 기울기가 $w=1$, y-절편이 $b=2$인 함수에 $x=10$을 입력하면 출력은 $f(10)=12$입니다.\n",
    "  - $f(10)=1 \\times 10 + 2 = 12$\n",
    "- 이처럼 함수에 입력을 넣어 그 결과를 계산하는 문제는 매우 쉬운 일입니다.\n",
    "- 어떻게 보면 함수 $f(x)$는 입력 $x$를 이용해 원하는 결과를 얻는 알고리즘입니다.\n",
    "- 머신 러닝이 해결하고자 하는 문제는 이 상황과는 반대로, 입력 $10$과 출력 $12$만 있을 때 \"이 입력과 출력을 얻어낸 함수(즉 알고리즘) $f(x)$는 도대체 무엇인가?\"를 답하는 것입니다.\n",
    "  - ![Alt text](simple-1.png)\n",
    "- 여기서 함수 $f(x)$의 형태가 $wx+b$라고 한 것은 단순히 우리가 세운 가설입니다.\n",
    "- $f(x)$는 사실 이차함수일 수도 있고 삼차함수일 수도 있고 다른 무언가일 수도 있습니다.\n",
    "- 다만, 가설을 세움으로 인해서 \"$f(x)$는 무엇인가?\" 라는 질문은 \"$f(x)$가 일차함수라고 해보자. 그렇다면 $w$와 $b$는 무엇인가?\"라는 질문으로 바뀌게 됩니다.\n",
    "  - ![Alt text](simple-2.png)\n",
    "- 머신러닝은 이 문제에서 구하고자 하는 $w$, $b$를 학습 가능한 파라미터(learnable parameter)라고 부릅니다.\n",
    "- 또한 입력 데이터 $10$를 입력 샘플(input sample)이라고 부릅니다. 출력 데이터 $12$는 타겟(target)이라고 부릅니다.\n",
    "- 다음 소스코드는, 파이토치 라이브러리를 사용해 위의 문제를 해결하는 프로그램입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 - output = 11.0, loss = 1.0\n",
      "epoch 2 - output = 11.20199966430664, loss = 0.6368045210838318\n",
      "epoch 3 - output = 11.36319637298584, loss = 0.40551885962486267\n",
      "epoch 4 - output = 11.491829872131348, loss = 0.2582368850708008\n",
      "epoch 5 - output = 11.594480514526367, loss = 0.16444605588912964\n",
      "epoch 6 - output = 11.676395416259766, loss = 0.10471992939710617\n",
      "epoch 7 - output = 11.741764068603516, loss = 0.06668579578399658\n",
      "epoch 8 - output = 11.793927192687988, loss = 0.04246600344777107\n",
      "epoch 9 - output = 11.835554122924805, loss = 0.02704244665801525\n",
      "epoch 10 - output = 11.86877155303955, loss = 0.017220905050635338\n",
      "epoch 11 - output = 11.895279884338379, loss = 0.010966302827000618\n",
      "epoch 12 - output = 11.91643238067627, loss = 0.006983547005802393\n",
      "epoch 13 - output = 11.933313369750977, loss = 0.00444710673764348\n",
      "epoch 14 - output = 11.946783065795898, loss = 0.0028320420533418655\n",
      "epoch 15 - output = 11.95753288269043, loss = 0.0018034561071544886\n",
      "epoch 16 - output = 11.966111183166504, loss = 0.001148451934568584\n",
      "epoch 17 - output = 11.972957611083984, loss = 0.0007312907837331295\n",
      "epoch 18 - output = 11.97842025756836, loss = 0.0004656852688640356\n",
      "epoch 19 - output = 11.982778549194336, loss = 0.0002965783642139286\n",
      "epoch 20 - output = 11.98625659942627, loss = 0.0001888810656964779\n",
      "epoch 21 - output = 11.989033699035645, loss = 0.00012025975593132898\n",
      "epoch 22 - output = 11.991249084472656, loss = 7.657852256670594e-05\n",
      "epoch 23 - output = 11.993017196655273, loss = 4.875954255112447e-05\n",
      "epoch 24 - output = 11.994427680969238, loss = 3.105073847109452e-05\n",
      "epoch 25 - output = 11.995553970336914, loss = 1.9767179765040055e-05\n",
      "epoch 26 - output = 11.996451377868652, loss = 1.2592719031090382e-05\n",
      "epoch 27 - output = 11.99716854095459, loss = 8.017160325834993e-06\n",
      "epoch 28 - output = 11.997740745544434, loss = 5.104230694996659e-06\n",
      "epoch 29 - output = 11.99819564819336, loss = 3.2556854421272874e-06\n",
      "epoch 30 - output = 11.998560905456543, loss = 2.070993105007801e-06\n",
      "epoch 31 - output = 11.99885082244873, loss = 1.3206090443418361e-06\n",
      "epoch 32 - output = 11.999082565307617, loss = 8.416864147875458e-07\n",
      "epoch 33 - output = 11.999268531799316, loss = 5.350457286112942e-07\n",
      "epoch 34 - output = 11.999417304992676, loss = 3.3953347156057134e-07\n",
      "epoch 35 - output = 11.999534606933594, loss = 2.1659070625901222e-07\n",
      "epoch 36 - output = 11.999629020690918, loss = 1.3762564776698127e-07\n",
      "epoch 37 - output = 11.999703407287598, loss = 8.796723705017939e-08\n",
      "epoch 38 - output = 11.999763488769531, loss = 5.593756213784218e-08\n",
      "epoch 39 - output = 11.999812126159668, loss = 3.529657988110557e-08\n",
      "epoch 40 - output = 11.999850273132324, loss = 2.2418134904000908e-08\n",
      "epoch 41 - output = 11.99988079071045, loss = 1.4210854715202004e-08\n",
      "epoch 42 - output = 11.99990463256836, loss = 9.094947017729282e-09\n",
      "epoch 43 - output = 11.999923706054688, loss = 5.820766091346741e-09\n",
      "epoch 44 - output = 11.99993896484375, loss = 3.725290298461914e-09\n",
      "epoch 45 - output = 11.99995231628418, loss = 2.2737367544323206e-09\n",
      "epoch 46 - output = 11.999961853027344, loss = 1.4551915228366852e-09\n",
      "epoch 47 - output = 11.999968528747559, loss = 9.904397302307189e-10\n",
      "epoch 48 - output = 11.999975204467773, loss = 6.148184183984995e-10\n",
      "epoch 49 - output = 11.999979019165039, loss = 4.4019543565809727e-10\n",
      "epoch 50 - output = 11.999984741210938, loss = 2.3283064365386963e-10\n",
      "epoch 51 - output = 11.999987602233887, loss = 1.5370460459962487e-10\n",
      "epoch 52 - output = 11.999990463256836, loss = 9.094947017729282e-11\n",
      "Single()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Single(nn.Module): # 나만의 모델을 정의하겠습니다\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.tensor([1.])) # w를 일단 1로 정하겠습니다. 나중에 학습하면서 서서히 고치겠습니다.\n",
    "        self.bias = nn.Parameter(torch.tensor([1.])) # b를 일단 1로 정합니다. 나중에 학습하면서 서서히 고치겠습니다.\n",
    "    def forward(self, input):\n",
    "        return self.weight * input + self.bias # 내 모델은 문제의 해답이 일차 함수라는 가설입니다. 기울기는 weight, y절편은 bias 입니다.\n",
    "\n",
    "model = Single()\n",
    "input = torch.tensor([10.0]) # 알려진 입력입니다.\n",
    "target = torch.tensor([12.0]) # 알려진 출력입니다.\n",
    "criterion = nn.MSELoss() # 오류는 평균 제곱으로 측정하겠습니다.\n",
    "learning_rate = 0.001 # 학습률입니다.\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate) # 스토캐스틱 그래디언트 디센트 전략을 사용해 학습하겠습니다.\n",
    "max_epoch = 1000 # 1000번 학습해도 안 되면 포기하겠습니다.\n",
    "losses = [] # 시기 별 로스를 기록하겠습니다.\n",
    "for i in range(max_epoch):\n",
    "    predict = model.forward(10) # 현재 모델이 예측을 합니다.\n",
    "    optimizer.zero_grad() # 이전 루프에서 계산했던 편미분을 모두 초기화 하겠습니다.\n",
    "    loss = criterion(predict, target) # 예측과 타겟 사이의 오류를 검사합니다\n",
    "    print(f\"epoch {i+1} - output = {predict.item()}, loss = {loss.item()}\") # 몇 번째 학습인지 표시합니다.\n",
    "    losses.append(loss.item()) # 시기 별 로스를 기록하겠습니다.\n",
    "    if loss.item() < 1.e-10: # 오차가 엄청 작으면 그냥 학습을 그만두겠습니다\n",
    "        break\n",
    "    else: # 예측과 타겟에 오류가 있었다면\n",
    "        loss.backward() # 파라미터들에게 오류를 전파하고, 파라미터에 대한 오류의 편미분을 계산합니다.\n",
    "        optimizer.step() # 스토캐스틱 그래디언트 디센트 전략을 통해 계산한 편미분을 참고하여 파라미터를 조절하겠습니다.\n",
    "print(model)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "x = range(1, i+2)\n",
    "y = [math.log(loss) for loss in losses]\n",
    "plt.gca().set_ylim(-30, 100)\n",
    "plt.title('epoch to loss graph', fontsize=10)\n",
    "plt.xlabel('epoch', fontsize=8)\n",
    "plt.ylabel('log(loss)', fontsize=8)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습률(learning rate)의 선택\n",
    "\n",
    "- `learning_rate` 변수의 값을 바꾸어가며 실행하며 학습을 시켜보면 보통 결과는 세 가지 정도의 현상이 보입니다.\n",
    "  1. 학습률이 너무 낮아서 정답 근처에서 정체합니다. (`learning_rate = 0.001`)\n",
    "  2. 학습률이 적당해서 어느 정도에서 학습이 끝납니다. (`learning_rate = 0.005`)\n",
    "  3. 학습률이 너무 커서 오히려 정답에서 멀어집니다. (`learning_rate = 0.01`)\n",
    "- 각각의 경우 출력이 어떻게 나오는 지 살펴보겠습니다.\n",
    "\n",
    "### 학습률이 너무 낮은 경우\n",
    "\n",
    "- `learning_rate = 0.0001`로 실행한 결과 다음 출력을 얻었습니다.\n",
    "  > epoch 24 - output = 11.374594688415527, loss = 0.39113181829452515  \n",
    "  > epoch 25 - output = 11.387228965759277, loss = 0.3754883408546448  \n",
    "  > ...  \n",
    "  > epoch 998 - output = 11.999970436096191, loss = 8.74024408403784e-10  \n",
    "  > epoch 999 - output = 11.999970436096191, loss = 8.74024408403784e-10  \n",
    "  > epoch 1000 - output = 11.999970436096191, loss = 8.74024408403784e-10  \n",
    "  > ![Alt text](simple-3.png)\n",
    "- 학습은 성공하여서, 타겟과 매우 가까운 에측을 내어 놓았습니다.\n",
    "- 하지만 500차 시기 근처를 살펴보면, 시기가 반복되더라도 더 이상 로스나 파라미터가 변하지 않는 것을 알 수 있습니다.\n",
    "- 이는 파라미터의 수정량이 지나치게 정밀해서 컴퓨터가 나타낼 수 있는 정밀도를 넘어선 경우입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :  2.0\n",
      "y :  1e-15\n",
      "z :  1e-16\n",
      "x + y =  2.000000000000001\n",
      "x + z =  2.0\n"
     ]
    }
   ],
   "source": [
    "x = 2.0\n",
    "y = 0.1e-14\n",
    "z = 0.1e-15\n",
    "print(\"x : \", x)\n",
    "print(\"y : \", y)\n",
    "print(\"z : \", z)\n",
    "print(\"x + y = \", x + y) # 좋아요, 이정도는 할 수 있습니다.\n",
    "print(\"x + z = \", x + z) # 이런! 그렇게 까지 정밀한 계산은 못 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 만약 학습을 반복하더라도, 더 이상 파라미터에 변화가 없다면 더 이상 시기를 반복할 이유가 없으므로, 시간을 낭비한 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습률이 적당한 경우\n",
    "\n",
    "- `learnin_rate = 0.005`로 실행한 결과 다음 출력을 얻었습니다.\n",
    "  >  epoch 1 - output = 11.0, loss = 1.0  \n",
    "  >  epoch 2 - output = 11.20199966430664, loss = 0.6368045210838318  \n",
    "  >  epoch 3 - output = 11.36319637298584, loss = 0.40551885962486267  \n",
    "  >  ...  \n",
    "  >  epoch 50 - output = 11.999984741210938, loss = 2.3283064365386963e-10  \n",
    "  >  epoch 51 - output = 11.999987602233887, loss = 1.5370460459962487e-10  \n",
    "  >  epoch 52 - output = 11.999990463256836, loss = 9.094947017729282e-11  \n",
    "  >  ![simple-4](simple-4.png)  \n",
    "- 학습률이 적당한 경우 학습률이 낮을 때 보다 더 적은 52 시기에서 기준을 충족하여 학습을 마쳤음을 알 수 있습니다.\n",
    "\n",
    "### 학습률이 너무 높은 경우\n",
    "\n",
    "- `learning_rate = 0.01`로 실행한 결과 다음 출력을 얻었습니다.\n",
    "  > epoch 1 - output = 11.0, loss = 1.0  \n",
    "  > epoch 2 - output = 13.020000457763672, loss = 1.0404009819030762  \n",
    "  > epoch 3 - output = 10.959599494934082, loss = 1.0824332237243652  \n",
    "  > epoch 4 - output = 13.06120777130127, loss = 1.1261619329452515  \n",
    "  > epoch 5 - output = 10.91756820678711, loss = 1.1716586351394653  \n",
    "  > epoch 6 - output = 13.104080200195312, loss = 1.218993067741394  \n",
    "  > ...  \n",
    "  > epoch 998 - output = 375277088.0, loss = 1.4083289675884134e+17  \n",
    "  > epoch 999 - output = -382782592.0, loss = 1.4652251724526387e+17  \n",
    "  > epoch 1000 - output = 390438240.0, loss = 1.524420129713029e+17  \n",
    "  > ![simple-5](simple-5.png)\n",
    "- 학습률이 지나치게 높은 경우, 행동을 고치려고 한 결과 오히려 로스가 더 커지게 되는 것을 알 수 있습니다.\n",
    "- 그런 경우 학습을 거치면 거칠수록 정답에서 멀어지기 때문에 학습은 실패합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.Linear\n",
    "\n",
    "- 우리가 방금 구현했던 `Single`은 사실 `torch.nn.Linear()`의 특수한 경우입니다.\n",
    "- `Single` 대신 `torch.nn.Linear(1,1)`을 하면 $w$와 $b$가 0차원 텐서인 선형 모델이 됩니다.\n",
    "- 다음 코드는 $w$와 $b$의 초기값이 랜덤하다는 것을 제외하고 위의 소스코드와 거의 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 - output = -7.890069484710693, loss = 395.6148681640625\n",
      "epoch 2 - output = -3.872274875640869, loss = 251.92909240722656\n",
      "epoch 3 - output = -0.6660752892494202, loss = 160.42947387695312\n",
      "epoch 4 - output = 1.8924721479415894, loss = 102.16211700439453\n",
      "epoch 5 - output = 3.9341931343078613, loss = 65.0572509765625\n",
      "epoch 6 - output = 5.563486576080322, loss = 41.42870330810547\n",
      "epoch 7 - output = 6.8636627197265625, loss = 26.381959915161133\n",
      "epoch 8 - output = 7.90120267868042, loss = 16.800140380859375\n",
      "epoch 9 - output = 8.729159355163574, loss = 10.69839859008789\n",
      "epoch 10 - output = 9.389869689941406, loss = 6.812780380249023\n",
      "epoch 11 - output = 9.917116165161133, loss = 4.338405132293701\n",
      "epoch 12 - output = 10.337858200073242, loss = 2.7627153396606445\n",
      "epoch 13 - output = 10.67361068725586, loss = 1.7593085765838623\n",
      "epoch 14 - output = 10.94154167175293, loss = 1.1203340291976929\n",
      "epoch 15 - output = 11.155350685119629, loss = 0.7134324908256531\n",
      "epoch 16 - output = 11.325969696044922, loss = 0.4543168544769287\n",
      "epoch 17 - output = 11.462124824523926, loss = 0.28930971026420593\n",
      "epoch 18 - output = 11.570775032043457, loss = 0.18423406779766083\n",
      "epoch 19 - output = 11.657478332519531, loss = 0.11732109636068344\n",
      "epoch 20 - output = 11.726667404174805, loss = 0.07471070438623428\n",
      "epoch 21 - output = 11.781881332397461, loss = 0.047575753182172775\n",
      "epoch 22 - output = 11.825942039489746, loss = 0.030296172946691513\n",
      "epoch 23 - output = 11.861101150512695, loss = 0.019292891025543213\n",
      "epoch 24 - output = 11.889158248901367, loss = 0.01228589378297329\n",
      "epoch 25 - output = 11.911548614501953, loss = 0.007823647931218147\n",
      "epoch 26 - output = 11.929415702819824, loss = 0.004982143174856901\n",
      "epoch 27 - output = 11.943673133850098, loss = 0.0031727158930152655\n",
      "epoch 28 - output = 11.95505142211914, loss = 0.0020203746389597654\n",
      "epoch 29 - output = 11.964130401611328, loss = 0.0012866280740126967\n",
      "epoch 30 - output = 11.9713773727417, loss = 0.0008192547829821706\n",
      "epoch 31 - output = 11.977158546447754, loss = 0.0005217320285737514\n",
      "epoch 32 - output = 11.981772422790527, loss = 0.0003322445845697075\n",
      "epoch 33 - output = 11.985453605651855, loss = 0.00021159759489819407\n",
      "epoch 34 - output = 11.988390922546387, loss = 0.00013477068569045514\n",
      "epoch 35 - output = 11.990737915039062, loss = 8.578621782362461e-05\n",
      "epoch 36 - output = 11.992608070373535, loss = 5.464062269311398e-05\n",
      "epoch 37 - output = 11.994101524353027, loss = 3.4792014048434794e-05\n",
      "epoch 38 - output = 11.995293617248535, loss = 2.215003769379109e-05\n",
      "epoch 39 - output = 11.996244430541992, loss = 1.4104301953921095e-05\n",
      "epoch 40 - output = 11.997002601623535, loss = 8.984397027234081e-06\n",
      "epoch 41 - output = 11.997608184814453, loss = 5.720779881812632e-06\n",
      "epoch 42 - output = 11.998090744018555, loss = 3.6452584026847035e-06\n",
      "epoch 43 - output = 11.998476028442383, loss = 2.3224893084261566e-06\n",
      "epoch 44 - output = 11.998784065246582, loss = 1.4784973245696165e-06\n",
      "epoch 45 - output = 11.999031066894531, loss = 9.388313628733158e-07\n",
      "epoch 46 - output = 11.999226570129395, loss = 5.981937647447921e-07\n",
      "epoch 47 - output = 11.999383926391602, loss = 3.795466909650713e-07\n",
      "epoch 48 - output = 11.999506950378418, loss = 2.430979293421842e-07\n",
      "epoch 49 - output = 11.99960708618164, loss = 1.5438126865774393e-07\n",
      "epoch 50 - output = 11.999687194824219, loss = 9.784707799553871e-08\n",
      "epoch 51 - output = 11.999749183654785, loss = 6.290883902693167e-08\n",
      "epoch 52 - output = 11.999799728393555, loss = 4.0108716348186135e-08\n",
      "epoch 53 - output = 11.99984073638916, loss = 2.5364897737745196e-08\n",
      "epoch 54 - output = 11.999873161315918, loss = 1.6088051779661328e-08\n",
      "epoch 55 - output = 11.999898910522461, loss = 1.0219082469120622e-08\n",
      "epoch 56 - output = 11.999918937683105, loss = 6.5710992203094065e-09\n",
      "epoch 57 - output = 11.9999361038208, loss = 4.082721716258675e-09\n",
      "epoch 58 - output = 11.999948501586914, loss = 2.6520865503698587e-09\n",
      "epoch 59 - output = 11.999958992004395, loss = 1.6816557035781443e-09\n",
      "epoch 60 - output = 11.999967575073242, loss = 1.051375875249505e-09\n",
      "epoch 61 - output = 11.999975204467773, loss = 6.148184183984995e-10\n",
      "epoch 62 - output = 11.999979019165039, loss = 4.4019543565809727e-10\n",
      "epoch 63 - output = 11.999984741210938, loss = 2.3283064365386963e-10\n",
      "epoch 64 - output = 11.999987602233887, loss = 1.5370460459962487e-10\n",
      "epoch 65 - output = 11.999990463256836, loss = 9.094947017729282e-11\n",
      "Linear(in_features=1, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Linear(1, 1)\n",
    "input = torch.tensor([10.0]) # 알려진 입력입니다.\n",
    "target = torch.tensor([12.0]) # 알려진 출력입니다.\n",
    "criterion = nn.MSELoss() # 오류는 평균 제곱으로 측정하겠습니다.\n",
    "learning_rate = 0.001 # 학습률입니다.\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate) # 스토캐스틱 그래디언트 디센트 전략을 사용해 학습하겠습니다.\n",
    "max_epoch = 1000 # 10000번 학습해도 안 되면 포기하겠습니다.\n",
    "for i in range(max_epoch):\n",
    "    predict = model.forward(torch.tensor([10.])) # 현재 모델이 예측을 합니다.\n",
    "    optimizer.zero_grad() # 이전 루프에서 계산했던 편미분을 모두 초기화 하겠습니다.\n",
    "    loss = criterion(predict, target) # 예측과 타겟 사이의 오류를 검사합니다\n",
    "    print(f\"epoch {i+1} - output = {predict.item()}, loss = {loss.item()}\") # 몇 번째 학습인지 표시합니다.\n",
    "    if loss.item() < 1.e-10: # 오차가 엄청 작으면 그냥 학습을 그만두겠습니다\n",
    "        break\n",
    "    else: # 예측과 타겟에 오류가 있었다면\n",
    "        loss.backward() # 파라미터들에게 오류를 전파하고, 파라미터에 대한 오류의 편미분을 계산합니다.\n",
    "        optimizer.step() # 스토캐스틱 그래디언트 디센트 전략을 통해 계산한 편미분을 참고하여 파라미터를 조절하겠습니다.\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
