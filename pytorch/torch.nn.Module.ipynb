{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.nn.Module\n",
    "\n",
    "[![](https://mermaid.ink/img/pako:eNplUctqAzEM_BWhc9wPMKWn9lgotEdftGttYrqWF9kmhHT_vWZjktL1RcNoRi9fcUye0aIxxkkJZWYLJekoTyJONnacKefXQEel6ATa2xj4YslJrzdqvQWhyHmhkUGkZx6G9-TrzPCHX_9LPqg14cK6F_XQiyRjXvoE0CbmuCQlvUAuVFpWYajTxLr33Ds025nD8VSAxMMQKO_FHVvIdYgb7qLe-fnHmEdFPGBkjRR8O-i2gMNy4sgObYOe9Nuhk7XpqJb0eZERbdHKB6yLb3P3I6OdaM539s2H9iOdXH8B4JaMaw?type=png)](https://mermaid.live/edit#pako:eNplUctqAzEM_BWhc9wPMKWn9lgotEdftGttYrqWF9kmhHT_vWZjktL1RcNoRi9fcUye0aIxxkkJZWYLJekoTyJONnacKefXQEel6ATa2xj4YslJrzdqvQWhyHmhkUGkZx6G9-TrzPCHX_9LPqg14cK6F_XQiyRjXvoE0CbmuCQlvUAuVFpWYajTxLr33Ds025nD8VSAxMMQKO_FHVvIdYgb7qLe-fnHmEdFPGBkjRR8O-i2gMNy4sgObYOe9Nuhk7XpqJb0eZERbdHKB6yLb3P3I6OdaM539s2H9iOdXH8B4JaMaw)\n",
    "\n",
    "- Module은 컴포지트 디자인 패턴에 따라 설계되었으며, 각 노드가 모듈인 트리 구조이다.\n",
    "- `torch.nn.Module`은 인공신경망을 구성하는 모든 모듈이 상속하는 베이스 클래스이다.\n",
    "- 사용자가 직접 정의하는 모델 또한 이 클래스를 상속해야 한다.\n",
    "- 모듈은 다른 모듈을 포함할 수 있다.\n",
    "- 그러므로 인공신경망을 중첩된 트리 구조로 만들 수 있다.\n",
    "- 서브모듈은, 부모 모듈의 속성으로 포함된다.\n",
    "- 부모 모듈의 속성으로 배정된 서브모듈은 자동으로 부모 모듈에 등록(register)된다.\n",
    "- 따라서 `torch.Module.children()`의 이터레이터에서 반환된다.\n",
    "- 다음 코드는 `MyModel`이란 클래스를 정의하고, 생성자에서 두 개의 서브모듈(Conv2d)을 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      ")\n",
      "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModel(nn.Module): # 나만의 모델. `nn.Moudule`을 상속합니다.\n",
    "    def __init__(self):\n",
    "        super().__init__() # `nn.Module.__init__()`을 호출합니다.\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5) # 서브모듈 `conv1`을 지정합니다.\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5) # 서브모듈 `conv2`를 지정합니다.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 나만의 모델은 입력을 conv1, conv2에 순서대로 통과시키고,\n",
    "        # 각각 `relu` 활성화 함수를 적용합니다.\n",
    "        x = F.relu(self.conv1(x)) \n",
    "        return F.relu(self.conv2(x))\n",
    "\n",
    "model = MyModel()\n",
    "print(model)\n",
    "# 내 모델에 등록된 자식 서브모듈을 확인하겠습니다.\n",
    "for submodule in model.children():\n",
    "    print(submodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈 추가 및 검색\n",
    "\n",
    "- 서브모듈을 등록할 때는 직접 `module.속성이름 = submodule`처럼 해도 되지만,\n",
    "- `Module.add_module(속성이름, submodule)`을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.add_module('seq', torch.nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2)))\n",
    "print(model)\n",
    "print(model.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `get_submodule()`함수로 어떤 서브모듈을 트리 구조 안에서 찾을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model.conv1 is model.get_submodule('conv1'))\n",
    "print(model.conv2 is model.get_submodule('conv2'))\n",
    "print(model.seq is model.get_submodule('seq'))\n",
    "print(model.seq[0] is model.get_submodule('seq.0'))\n",
    "print(model.seq[1] is model.get_submodule('seq.1'))\n",
    "# model.get_submodule('foo') # AttributeError: MyModel has no attribute 'foo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `module.named_modules()`는 자기자신을 포함한 모든 자손 노드들을 이름과 함께 루프 돌 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "name :  \n",
      "module :  MyModel(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "name :  conv1\n",
      "module :  Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "================================================================================\n",
      "name :  conv2\n",
      "module :  Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "================================================================================\n",
      "name :  seq\n",
      "module :  Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "================================================================================\n",
      "name :  seq.0\n",
      "module :  Linear(in_features=2, out_features=2, bias=True)\n",
      "================================================================================\n",
      "name :  seq.1\n",
      "module :  Linear(in_features=2, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(\"=\"*80)\n",
    "    print(\"name : \", name)\n",
    "    print(\"module : \", module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터(Parameter)\n",
    "\n",
    "- 모듈은 가중치(weight)와 편향(bias)을 파라미터(Parameter) 객체로 저장한다.\n",
    "- 모듈이 입력을 받아 예측을 하는 것을 `forward`라 부른다.\n",
    "- 예측의 파라미터에 대한 편미분을 구하는 과정을 `bakcward`라 부른다.\n",
    "- 그리고 그 편미분을 그래디언트(`gradient`)라 부른다.\n",
    "- 파라미터를 그래디언트를 사용해 한 번 업데이트 하는 것을 `step`이라 한다.\n",
    "- 그리고 업데이트 되는 파라미터는 학습 가능한 파라미터(`learnable parameter`)라 부른다.\n",
    "- `torch.nn.Parameter`는 `torch.Tensor`를 상속한다.\n",
    "- `torch.Module`의 속성으로 배정될 때 자동으로 모듈의 파라미터 목록에 등록된다.\n",
    "- 따라서 `torch.Module.parameter()`의 이터레이터에서 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.5992, -0.1465], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0867, -0.8577],\n",
      "        [ 1.1794, -0.4369]], requires_grad=True)\n",
      "True\n",
      "my_param_1을 찾았습니다.\n",
      "my_param_2를 찾았습니다.\n"
     ]
    }
   ],
   "source": [
    "# model.seq.0.bias 파라미터를 구해보겠습니다.\n",
    "print(model.get_parameter('seq.0.bias'))\n",
    "# my_param_1을 모델에 등록하겠습니다.\n",
    "model.my_param_1 = torch.nn.parameter.Parameter(torch.randn(2,2))\n",
    "# my_param_2를 모델에 등록하겠습니다.\n",
    "model.register_parameter('my_param_2', torch.nn.parameter.Parameter(torch.zeros(2,2)))\n",
    "# my_param_1을 구하겠습니다.\n",
    "print(model.my_param_1)\n",
    "# my_param_1을 `get_parameter`함수를 통해 구해보겠습니다.\n",
    "print(model.my_param_1 is model.get_parameter('my_param_1'))\n",
    "for param in model.parameters():\n",
    "    # parameters()가 my_param_1을 포함하나요?\n",
    "    if param is model.my_param_1:\n",
    "        print(\"my_param_1을 찾았습니다.\")\n",
    "    # parameters()가 my_param_2를 포함하나요?\n",
    "    if param is model.my_param_2:\n",
    "        print(\"my_param_2를 찾았습니다.\")\n",
    "# my_param_1을 삭제하겠습니다.\n",
    "model.register_parameter('my_param_1', None)\n",
    "# my_param_2를 삭제하겠습니다.\n",
    "model.my_param_2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 버퍼(buffer)\n",
    "\n",
    "- `register_buffer(name, tensor, persistent=True)`를 통해 버퍼를 등록할 수 있다.\n",
    "- 파라미터는 아니지만, 모델이 계산할 때 사용해야 하는 텐서를 등록할 때 사용한다.\n",
    "  - 예를 들어 `BatchNorm`의 `running_mean` 등\n",
    "- 버퍼는 파라미터처럼 유지(persist)된다. 그 말은 `save()` `load()`를 통해 저장된다는 뜻이다.\n",
    "- `persistent=False`를 하면 유지되지 않는다.\n",
    "- 퍼시스트 되는 속성은 모듈의 `state_dict`에 나열된다.\n",
    "- 버퍼 또한 파라미터처럼 모듈의 속성으로 배정된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [0., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model.register_buffer('my_buffer_1', torch.eye(2))\n",
    "model.register_buffer('my_buffer_2', torch.eye(3))\n",
    "for buffer in model.buffers():\n",
    "    print(buffer)\n",
    "print(model.my_buffer_1 is model.get_buffer('my_buffer_1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일괄 작업, 캐스팅 및 장치 전환\n",
    "\n",
    "- 트리 구조에서 자신을 포함한 모든 자손에 각각 어떤 함수를 적용하고 싶다면, `Module.apply()`함수를 사용한다.\n",
    "- 이 함수는 트리 내의 모든 모듈의 파라미터를 초기화 하는 데에 자주 쓰인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      " * Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      " * Linear(in_features=2, out_features=2, bias=True)\n",
      " * Linear(in_features=2, out_features=2, bias=True)\n",
      " * Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      " * MyModel(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def print_model(m):\n",
    "    print(f\" * {m}\")\n",
    "returned = model.apply(print_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `apply`는 적용할 함수를 직접 지정하지만, 일괄적으로 적용하는 작업중 자주 사용하는 것들은 함수가 만들어져 있다.\n",
    "- `zero_grad()` 함수는 모든 파라미터의 그래디언트를 0으로 설정한다.\n",
    "- `bfloat16()`, `double()`, `float()`, `half()`, `type(dst_type)` 함수는 모듈과 자손 모듈에 속한 모든 파라미터와 버퍼에 타입 캐스팅을 실시한다.\n",
    "- `cuda()`, `ipu()`, `xpu()`, `to(device)` 함수는 모듈과 자손 모듈에 속한 모든 파라미터와 버퍼를 특정 장치로 이동시킨다.\n",
    "- `to(device)`의 경우, 장치가 지원하는 것에 알맞게 타입 캐스팅도 함께 수행하도록 지정할 수 있으나, 정수 타입인 텐서는 캐스팅 대상에서 제외된다.\n",
    "- `to_empty`는 다른 장치로 파라미터와 버퍼를 전송하지만, 그 스토리지를 복사하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈의 훈련 모드\n",
    "\n",
    "- 모듈은 두 가지 모드(mode)가 있으며, 훈련 모드와(train mode)와 평가 모드(eval mode)이다.\n",
    "- 이 모드는 `DropOut`, `BatchNorm` 등 특정 모듈의 행동에 영향을 미친다.\n",
    "- `Module.train(True)`로 훈련 모드를 활성화 할 수 있다.\n",
    "- `Module.train(False)` 혹은 `Module.eval()`로 평가 모드를 활성화 할 수 있다.\n",
    "- 모듈이 현재 훈련 모드에 있는 지는 `Module.traning` 속성으로 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(model.training)\n",
    "model.train(False)\n",
    "print(model.training)\n",
    "model.train(True)\n",
    "print(model.training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UninitializedParameter와 UninitializedBuffer\n",
    "\n",
    "- `torch.UninitializedParameter`와 `torch.UninitializedBuffer`는 각각 아직 초기화되지 않은 파라미터와 버퍼를 나타내는 클래스이다.\n",
    "- 초기화되지 않았으므로, 대부분의 연산이나 쿼리는 `RuntimeError`를 일으킨다.\n",
    "- 다만 초기화가 되기 전에 미리 `dtype`과 `device`를 정해줄 수는 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state_dict를 활용한 모델의 저장 및 불러오기\n",
    "\n",
    "- `Module.state_dict`은 파이썬의 딕셔너리 형식(`collections.OrderedDict`)의 객체이다.\n",
    "- `state_dict`는 자기자신을 포함한 모듈 트리 내의 모든 파라미터와 버퍼의 상태를 담고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['my_buffer_1', 'my_buffer_2', 'conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'seq.0.weight', 'seq.0.bias', 'seq.1.weight', 'seq.1.bias'])\n",
      "Parameter containing:\n",
      "tensor([ 0.5992, -0.1465], requires_grad=True)\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())\n",
    "print(model.get_parameter('seq.0.bias'))\n",
    "print(model.get_buffer('my_buffer_1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `state_dict`는 모델의 파라미터를 쉽게 저장하고 로드할 수 있도록 도와준다.\n",
    "- `static_dict`은 다양한 활동에서 요긴하게 쓰인다:\n",
    "  - 모델 저장 및 로딩 : 훈련이 끝난 모델의 파라미터를 파일로 저장할 수 있다. 훈련이 마무리된 시점을 로딩해와 계속해서 더더욱 훈련시킬 수 있고 내 모델을 남들과 공유할 수 있다. 남들은 내 모델을 가져다가 자기 입맛에 맞게 훈련시키거나 자기 프로그램에 인퍼런스용으로 활용할 수 있다.\n",
    "  - 체크포인트: 어느 시점에서의 모델의 상태를 저장했다가 나중에 훈련이 잘못되었다고 생각하면 되돌아올 수 있다.\n",
    "  - 전이 학습: 전이 학습을 할때 쉽게 다른 모델의 파라미터를 복사해올 수 있다.\n",
    "  - 모델 호환성: 모델의 구조와 관계없이, 파라미터만을 가지고 있으므로 다른 모델로 이식하기 좋다.\n",
    "  - 파인튜닝: 파인튜닝을 위해 몇몇 레이어를 얼릴 때 state_dict를 통해 파라미터를 쭉 살펴보고 어느 것을 얼릴 지 고를 수 있다.\n",
    "- `torch.save()`를 호출하면 `state_dict`의 내용이 파일로 저장된다.\n",
    "- `torch.load()`를 호출하면 파일에 저장된 `state_dict`를 로드할 수 있다. 이후, 모델은 `Module.load_state_dict()`를 호출하여 `state_dict`의 내용으로 자신의 파라미터를 덮어쓴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "simple_model = SimpleModel()\n",
    "\n",
    "# Save the state_dict\n",
    "torch.save(simple_model.state_dict(), 'model_state_dict.pth') # 파일 쓰기 권한이 없으면 여기서 실패합니다.\n",
    "\n",
    "# Load the state_dict into a new instance of the model\n",
    "simple_model = SimpleModel()\n",
    "simple_model.load_state_dict(torch.load('model_state_dict.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훅\n",
    "\n",
    "- 모듈의 작업 과정의 여러 부분에 훅을 설정하여, 작업을 감시할 수 있다.\n",
    "  - `torch.nn.Module.register_backward_hook(hook)`\n",
    "  - `torch.nn.Module.register_forward_hook(hook, *, prepend=False, with_kwargs=False)`\n",
    "  - `torch.nn.Module.register_forward_pre_hook(hook, *, prepend=False, with_kwargs=False)`\n",
    "  - `torch.nn.Module.register_full_backward_hook(hook, prepend=False)`\n",
    "  - `torch.nn.Module.register_full_backward_pre_hook(hook, prepend=False)`\n",
    "  - `torch.nn.Module.register_load_state_dict_post_hook(hook)`\n",
    "  - `torch.nn.Module.register_state_dict_pre_hook(hook)`\n",
    "- 이 함수들은 `torch.utils.hooks.RemovableHandle`타입의 객체를 반환한다.\n",
    "- 이 `RemovableHandle` 객체의 `.remove()`함수를 부르면 훅이 제거된다.\n",
    "- 혹은 `RemovableHandle` 객체를 컨텍스트 매니저로 사용할 수 있다.\n",
    "- 훅은 모델을 디버깅할 때 중간중간 출력의 결과를 출력하는 것에 유용하다.\n",
    "- 다음 코드는 모듈의 자손들 중에 리프 노드인 것들만 골라서 출력의 형태를 콘솔에 써주도록 훅을 건다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))  →  torch.Size([1, 20, 6, 6])\n",
      "                                         Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))  →  torch.Size([1, 20, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 훅을 걸어주는 함수입니다.\n",
    "def report_output_shape(module):\n",
    "    handles = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if len(list(module.children())) == 0:\n",
    "            handles[name] = module.register_forward_hook(lambda module, _, output: print(str(module).partition('\\n')[0].rjust(90), \" → \", output.shape))\n",
    "    return handles\n",
    "\n",
    "# 테스트를 위해 입력을 준비합니다.\n",
    "input = torch.randn((1, 1, 10, 10))\n",
    "# 모델에 훅을 걸어줍니다.\n",
    "handles = report_output_shape(model)\n",
    "# forward를 호출합니다. 여기서 forward_hook이 호출됩니다.\n",
    "model.forward(input)\n",
    "\n",
    "# 모든 훅을 해제합니다.\n",
    "for handle in handles.values():\n",
    "    handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈 트리의 가시화\n",
    "\n",
    "- [netron](https://netron.app/)을 사용하여 모델의 예측 과정을 가시화 할 수 있다.\n",
    "- `torch.onnx.export`를 사용하여 내 모델이 입력에 대해 예측한 결과를 `.onnx`파일로 저장한다.\n",
    "- 저장한 파일을 netron 앱으로 열어본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1,1,24,24)\n",
    "torch.onnx.export(model, input, f='exported_model.onnx')"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 사진은 위에서 만든 `model`을 실행한 결과를 보여준다.  \n",
    "![image.png](attachment:image.png)\n",
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미리 정의된 모듈\n",
    "\n",
    "- 사용자는 자신의 모델을 만들기 위해 `Module` 클래스를 상속하여 `forward()` 함수를 오버라이드한다.\n",
    "- 그것 말고도 `torch` 라이브러리가 미리 구현해둔 수많은 모듈이 있다.\n",
    "  - 컨테이너(Container)\n",
    "    - Module : Base class for all neural network modules.\n",
    "    - Sequential : A sequential container.\n",
    "    - ModuleList : Holds submodules in a list.\n",
    "    - ModuleDict : Holds submodules in a dictionary.\n",
    "    - ParameterList : Holds parameters in a list.\n",
    "    - ParameterDict : Holds parameters in a dictionary.\n",
    "  - 컨볼루션 레이어(Convolution Layer)\n",
    "    - nn.Conv1d : Applies a 1D convolution over an input signal composed of several input planes.\n",
    "    - nn.Conv2d : Applies a 2D convolution over an input signal composed of several input planes.\n",
    "    - nn.Conv3d : Applies a 3D convolution over an input signal composed of several input planes.\n",
    "    - nn.ConvTranspose1d : Applies a 1D transposed convolution operator over an input image composed of several input planes.\n",
    "    - nn.ConvTranspose2d : Applies a 2D transposed convolution operator over an input image composed of several input planes.\n",
    "    - nn.ConvTranspose3d : Applies a 3D transposed convolution operator over an input image composed of several input planes.\n",
    "    - nn.LazyConv1d  : A torch.nn.Conv1d module with lazy initialization of the in_channels argument of the Conv1d that is inferred from the input.size(1).\n",
    "    - nn.LazyConv2d : A torch.nn.Conv2d module with lazy initialization of the in_channels argument of the Conv2d that is inferred from the input.size(1).\n",
    "    - nn.LazyConv3d : A torch.nn.Conv3d module with lazy initialization of the in_channels argument of the Conv3d that is inferred from the input.size(1).\n",
    "    - nn.LazyConvTranspose1d : A torch.nn.ConvTranspose1d module with lazy initialization of the in_channels argument of the ConvTranspose1d that is inferred from the input.size(1).\n",
    "    - nn.LazyConvTranspose2d : A torch.nn.ConvTranspose2d module with lazy initialization of the in_channels argument of the ConvTranspose2d that is inferred from the input.size(1).\n",
    "    - nn.LazyConvTranspose3d : A torch.nn.ConvTranspose3d module with lazy initialization of the in_channels argument of the ConvTranspose3d that is inferred from the input.size(1).\n",
    "    - nn.Unfold : Extracts sliding local blocks from a batched input tensor.\n",
    "  - 풀링 레이어(Pooling Layer)\n",
    "    - nn.Fold : Combines an array of sliding local blocks into a large containing tensor.\n",
    "    - nn.MaxPool1d : Applies a 1D max pooling over an input signal composed of several input planes.\n",
    "    - nn.MaxPool2d : Applies a 2D max pooling over an input signal composed of several input planes.\n",
    "    - nn.MaxPool3d : Applies a 3D max pooling over an input signal composed of several input planes.\n",
    "    - nn.MaxUnpool1d : Computes a partial inverse of MaxPool1d.\n",
    "    - nn.MaxUnpool2d : Computes a partial inverse of MaxPool2d.\n",
    "    - nn.MaxUnpool3d : Computes a partial inverse of MaxPool3d.\n",
    "    - nn.AvgPool1d : Applies a 1D average pooling over an input signal composed of several input planes.\n",
    "    - nn.AvgPool2d : Applies a 2D average pooling over an input signal composed of several input planes.\n",
    "    - nn.AvgPool3d : Applies a 3D average pooling over an input signal composed of several input planes.\n",
    "    - nn.FractionalMaxPool2d : Applies a 2D fractional max pooling over an input signal composed of several input planes.\n",
    "    - nn.FractionalMaxPool3d : Applies a 3D fractional max pooling over an input signal composed of several input planes.\n",
    "    - nn.LPPool1d : Applies a 1D power-average pooling over an input signal composed of several input planes.\n",
    "    - nn.LPPool2d : Applies a 2D power-average pooling over an input signal composed of several input planes.\n",
    "    - nn.AdaptiveMaxPool1d : Applies a 1D adaptive max pooling over an input signal composed of several input planes.\n",
    "    - nn.AdaptiveMaxPool2d : Applies a 2D adaptive max pooling over an input signal composed of several input planes.\n",
    "    - nn.AdaptiveMaxPool3d : Applies a 3D adaptive max pooling over an input signal composed of several input planes.\n",
    "    - nn.AdaptiveAvgPool1d : Applies a 1D adaptive average pooling over an input signal composed of several input planes.\n",
    "    - nn.AdaptiveAvgPool2d : Applies a 2D adaptive average pooling over an input signal composed of several input planes.\n",
    "    - nn.AdaptiveAvgPool3d : Applies a 3D adaptive average pooling over an input signal composed of several input planes.\n",
    "  - 패딩 레이어(Padding Layer)\n",
    "    - nn.ReflectionPad1d : Pads the input tensor using the reflection of the input boundary.\n",
    "    - nn.ReflectionPad2d : Pads the input tensor using the reflection of the input boundary.\n",
    "    - nn.ReflectionPad3d : Pads the input tensor using the reflection of the input boundary.\n",
    "    - nn.ReplicationPad1d : Pads the input tensor using replication of the input boundary.\n",
    "    - nn.ReplicationPad2d : Pads the input tensor using replication of the input boundary.\n",
    "    - nn.ReplicationPad3d : Pads the input tensor using replication of the input boundary.\n",
    "    - nn.ZeroPad2d : Pads the input tensor boundaries with zero.\n",
    "    - nn.ConstantPad1d : Pads the input tensor boundaries with a constant value.\n",
    "    - nn.ConstantPad2d : Pads the input tensor boundaries with a constant value.\n",
    "    - nn.ConstantPad3d : Pads the input tensor boundaries with a constant value.\n",
    "  - 비선형 활성화 함수(Non-linear Activations. weighted sum, nonlinearity)\n",
    "    - nn.ELU : Applies the Exponential Linear Unit (ELU) function, element-wise, as described in the paper: Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs).\n",
    "    - nn.Hardshrink : Applies the Hard Shrinkage (Hardshrink) function element-wise.\n",
    "    - nn.Hardsigmoid : Applies the Hardsigmoid function element-wise.\n",
    "    - nn.Hardtanh : Applies the HardTanh function element-wise.\n",
    "    - nn.Hardswish : Applies the Hardswish function, element-wise, as described in the paper: Searching for MobileNetV3.\n",
    "    - nn.LeakyReLU : Applies the element-wise function:\n",
    "    - nn.LogSigmoid : Applies the element-wise function:\n",
    "    - nn.MultiheadAttention : Allows the model to jointly attend to information from different representation subspaces as described in the paper: Attention Is All You Need.\n",
    "    - nn.PReLU : Applies the element-wise function:\n",
    "    - nn.ReLU : Applies the rectified linear unit function element-wise:\n",
    "    - nn.ReLU6 : Applies the element-wise function:\n",
    "    - nn.RReLU : Applies the randomized leaky rectified liner unit function, element-wise, as described in the paper:\n",
    "    - nn.SELU : Applied element-wise, as:\n",
    "    - nn.CELU : Applies the element-wise function:\n",
    "    - nn.GELU : Applies the Gaussian Error Linear Units function:\n",
    "    - nn.Sigmoid : Applies the element-wise function:\n",
    "    - nn.SiLU : Applies the Sigmoid Linear Unit (SiLU) function, element-wise.\n",
    "    - nn.Mish : Applies the Mish function, element-wise.\n",
    "    - nn.Softplus : Applies the Softplus function $Softplus(x)=\\frac{1}{β}​∗\\log(1+\\exp(β∗x))$ element-wise.\n",
    "    - nn.Softshrink : Applies the soft shrinkage function elementwise:\n",
    "    - nn.Softsign : Applies the element-wise function:\n",
    "    - nn.Tanh : Applies the Hyperbolic Tangent (Tanh) function element-wise.\n",
    "    - nn.Tanhshrink : Applies the element-wise function:\n",
    "    - nn.Threshold : Thresholds each element of the input Tensor.\n",
    "    - nn.GLU : Applies the gated linear unit function $GLU(a,b)=a⊗σ(b)$ where $a$ is the first half of the input matrices and $b$ is the second half.\n",
    "  - 비선형 활성화 함수(기타)\n",
    "    - nn.Softmin : Applies the Softmin function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range [0, 1] and sum to 1.\n",
    "    - nn.Softmax : Applies the Softmax function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range [0, 1] and sum to 1.\n",
    "    - nn.Softmax2d : Applies SoftMax over features to each spatial location.\n",
    "    - nn.LogSoftmax : Applies the $\\log(Softmax(x))$ function to an n-dimensional input Tensor.\n",
    "    - nn.AdaptiveLogSoftmaxWithLoss : Efficient softmax approximation as described in Efficient softmax approximation for GPUs by Edouard Grave, Armand Joulin, Moustapha Cissé, David Grangier, and Hervé Jégou.\n",
    "  - 정규화 레이어(Normalization Layers)\n",
    "    - nn.BatchNorm1d : Applies Batch Normalization over a 2D or 3D input as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .\n",
    "    - nn.BatchNorm2d : Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .\n",
    "    - nn.BatchNorm3d : Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .\n",
    "    - nn.LazyBatchNorm1d : A torch.nn.BatchNorm1d module with lazy initialization of the num_features argument of the BatchNorm1d that is inferred from the input.size(1).\n",
    "    - nn.LazyBatchNorm2d : A torch.nn.BatchNorm2d module with lazy initialization of the num_features argument of the BatchNorm2d that is inferred from the input.size(1).\n",
    "    - nn.LazyBatchNorm3d : A torch.nn.BatchNorm3d module with lazy initialization of the num_features argument of the BatchNorm3d that is inferred from the input.size(1).\n",
    "    - nn.GroupNorm : Applies Group Normalization over a mini-batch of inputs as described in the paper Group Normalization\n",
    "    - nn.SyncBatchNorm : Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .\n",
    "    - nn.InstanceNorm1d : Applies Instance Normalization over a 2D (unbatched) or 3D (batched) input as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.\n",
    "    - nn.InstanceNorm2d : Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.\n",
    "    - nn.InstanceNorm3d : Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.\n",
    "    - nn.LazyInstanceNorm1d : A torch.nn.InstanceNorm1d module with lazy initialization of the num_features argument of the InstanceNorm1d that is inferred from the input.size(1).\n",
    "    - nn.LazyInstanceNorm2d : A torch.nn.InstanceNorm2d module with lazy initialization of the num_features argument of the InstanceNorm2d that is inferred from the input.size(1).\n",
    "    - nn.LazyInstanceNorm3d : A torch.nn.InstanceNorm3d module with lazy initialization of the num_features argument of the InstanceNorm3d that is inferred from the input.size(1).\n",
    "    - nn.LayerNorm : Applies Layer Normalization over a mini-batch of inputs as described in the paper Layer Normalization\n",
    "    - nn.LocalResponseNorm : Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension.\n",
    "  - RNN 레이어(Recurrent Layers)\n",
    "    - nn.RNNBase : \n",
    "    - nn.RNN : Applies a multi-layer Elman RNN with tanh⁡tanh or ReLU non-linearity to an input sequence.\n",
    "    - nn.LSTM : Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.\n",
    "    - nn.GRU : Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
    "    - nn.RNNCell : An Elman RNN cell with tanh or ReLU non-linearity.\n",
    "    - nn.LSTMCell : A long short-term memory (LSTM) cell.\n",
    "    - nn.GRUCell : A gated recurrent unit (GRU) cell\n",
    "  - 트랜스포머 레이어(Transformer Layers)\n",
    "    - nn.Transformer : A transformer model.\n",
    "    - nn.TransformerEncoder : TransformerEncoder is a stack of N encoder layers.\n",
    "    - nn.TransformerDecoder : TransformerDecoder is a stack of N decoder layers\n",
    "    - nn.TransformerEncoderLayer : TransformerEncoderLayer is made up of self-attn and feedforward network.\n",
    "    - nn.TransformerDecoderLayer : TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.\n",
    "  - 선형 레이어(Linear Layers)\n",
    "    - nn.Identity : A placeholder identity operator that is argument-insensitive.\n",
    "    - nn.Linear : Applies a linear transformation to the incoming data: $y=xA^T+b$\n",
    "    - nn.Bilinear : Applies a bilinear transformation to the incoming data: $y=x^T_1​Ax_2​+b$\n",
    "    - nn.LazyLinear : A torch.nn.Linear module where in_features is inferred.\n",
    "  - 드롭아웃 레이어(Dropout Layers)\n",
    "    - nn.Dropout : During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.\n",
    "    - nn.Dropout1d : Randomly zero out entire channels (a channel is a 1D feature map, e.g., the $j$-th channel of the $i$-th sample in the batched input is a 1D tensor $\\text{input}[i,j]$).\n",
    "    - nn.Dropout2d : Randomly zero out entire channels (a channel is a 2D feature map, e.g., the $j$-th channel of the $i$-th sample in the batched input is a 2D tensor $\\text{input}[i,j]$).\n",
    "    - nn.Dropout3d : Randomly zero out entire channels (a channel is a 3D feature map, e.g., the $j$-th channel of the $i$-th sample in the batched input is a 3D tensor $\\text{input}[i,j]$).\n",
    "    - nn.AlphaDropout : Applies Alpha Dropout over the input.\n",
    "    - nn.FeatureAlphaDropout : Randomly masks out entire channels. a channel is a feature map.\n",
    "  - 희소 레이어(Sparse Layers)\n",
    "    - nn.Embedding : A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "    - nn.EmbeddingBag : Computes sums or means of 'bags' of embeddings, without instantiating the intermediate embeddings.\n",
    "  - 거리 함수(Distance Functions)\n",
    "    - nn.CosineSimilarity : Returns cosine similarity between $x_1$​ and $x_2$​, computed along dim.\n",
    "    - nn.PairwiseDistance : Computes the pairwise distance between input vectors, or between columns of input matrices.\n",
    "  - 로스 함수(Loss Functions)\n",
    "    - nn.L1Loss : Creates a criterion that measures the mean absolute error (MAE) between each element in the input $x$ and target $y$.\n",
    "    - nn.MSELoss : Creates a criterion that measures the mean squared error (squared L2 norm) between each element in the input $x$ and target $y$.\n",
    "    - nn.CrossEntropyLoss : This criterion computes the cross entropy loss between input logits and target.\n",
    "    - nn.CTCLoss : The Connectionist Temporal Classification loss.\n",
    "    - nn.NLLLoss : The negative log likelihood loss.\n",
    "    - nn.PoissonNLLLoss : Negative log likelihood loss with Poisson distribution of target.\n",
    "    - nn.GaussianNLLLoss : Gaussian negative log likelihood loss.\n",
    "    - nn.KLDivLoss : The Kullback-Leibler divergence loss.\n",
    "    - nn.BCELoss : Creates a criterion that measures the Binary Cross Entropy between the target and the input probabilities:\n",
    "    - nn.BCEWithLogitsLoss : This loss combines a Sigmoid layer and the BCELoss in one single class.\n",
    "    - nn.MarginRankingLoss : Creates a criterion that measures the loss given inputs $x_1$, $x_2$, two 1D mini-batch or 0D Tensors, and a label 1D mini-batch or 0D Tensor $y$ (containing 1 or -1).\n",
    "    - nn.HingeEmbeddingLoss : Measures the loss given an input tensor $x$ and a labels tensor $y$ (containing 1 or -1).\n",
    "    - nn.MultiLabelMarginLoss : Creates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input $x$ (a 2D mini-batch Tensor) and output $y$ (which is a 2D Tensor of target class indices).\n",
    "    - nn.HuberLoss : Creates a criterion that uses a squared term if the absolute element-wise error falls below delta and a delta-scaled L1 term otherwise.\n",
    "    - nn.SmoothL1Loss : Creates a criterion that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise.\n",
    "    - nn.SoftMarginLoss : Creates a criterion that optimizes a two-class classification logistic loss between input tensor $x$ and target tensor $y$ (containing 1 or -1).\n",
    "    - nn.MultiLabelSoftMarginLoss : Creates a criterion that optimizes a multi-label one-versus-all loss based on max-entropy, between input $x$ and target $y$ of size $(N,C)$.\n",
    "    - nn.CosineEmbeddingLoss : Creates a criterion that measures the loss given input tensors $x_1$​, $x_2$​ and a Tensor label $y$ with values 1 or -1.\n",
    "    - nn.MultiMarginLoss : Creates a criterion that optimizes a multi-class classification hinge loss (margin-based loss) between input $x$ (a 2D mini-batch Tensor) and output $y$ (which is a 1D tensor of target class indices, $0≤y≤x.size(1)−1$):\n",
    "    - nn.TripletMarginLoss : Creates a criterion that measures the triplet loss given an input tensors $x_1$, $x_2$, $x_3$ and a margin with a value greater than 00.\n",
    "    - nn.TripletMarginWithDistanceLoss : Creates a criterion that measures the triplet loss given input tensors $a$, $p$, and $n$ (representing anchor, positive, and negative examples, respectively), and a nonnegative, real-valued function (\"distance function\") used to compute the relationship between the anchor and positive example (\"positive distance\") and the anchor and negative example (\"negative distance\").\n",
    "  - 비전 레이어(Vision Layers)\n",
    "    - nn.PixelShuffle : Rearranges elements in a tensor of shape $(∗,C×r2,H,W)$ to a tensor of shape $(∗,C,H×r,W×r)$, where r is an upscale factor.\n",
    "    - nn.PixelUnshuffle : Reverses the PixelShuffle operation by rearranging elements in a tensor of shape $(∗,C,H×r,W×r)$ to a tensor of shape $(∗,C×r2,H,W)$, where r is a downscale factor.\n",
    "    - nn.Upsample : Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.\n",
    "    - nn.UpsamplingNearest2d : Applies a 2D nearest neighbor upsampling to an input signal composed of several input channels.\n",
    "    - nn.UpsamplingBilinear2d : Applies a 2D bilinear upsampling to an input signal composed of several input channels.\n",
    "  - 셔플 레이어(Shuffle Layers)\n",
    "    - nn.ChannelShuffle : Divide the channels in a tensor of shape $(∗,C,H,W)$ into g groups and rearrange them as $(∗,C,g​g,H,W)$, while keeping the original tensor shape.\n",
    "  - DataParallel 레이어(multi-GPU, 분산 컴퓨팅)\n",
    "    - nn.DataParallel : Implements data parallelism at the module level.\n",
    "    - nn.parallel.DistributedDataParallel : Implements distributed data parallelism that is based on torch.distributed package at the module level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
